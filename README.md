# Chatterbox
## On the path to AGI: Augmenting LLMs with a Chatterbox

The human brain consists of a non-algorithmic brain and an algorithmic brain.  A Large Language Model (LLM) can be seen as the non-algorithmic brain.  Basically, the LLM is a massive neural network. What is proposed here is to add an algorthmic brain that can be seen as the equivalent of what is known as a chatterbox to the LLM setup. 

The LLM can run on a traditional Personal Computer (PC).  The PC can be seen as the algorithmic brain. The PC runs programs one line after the other, unlike a neural network.  In summary, the PC can set a program running that feeds data to the LLM prompt while the LLM is running doing some task or asking some question.  For example, the PC could enter single words or sentances that are on a scale from supposidely unrelated to supposidely related.  This could be done on a probability basis like Bayesian, or some other data gathering.

Hence the reason for calling this the Chatterbox, becuase it models what happens in the human brain, that can be very useful sometimes but very annoying at others.  However, this process will introduce an element of randomness into the conversation or agentic workflow.
